#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
evaluate_model_metrics.py

This script evaluates the performance of the AD_cat_quant model on a set of predictions.
It reads './data/pred_updated.csv' (which must contain columns: image_path, label, pred_label, conf, ATP, pred_pct, pred_ATP),
reconstructs the bin ranges from the ATP mapping, and computes a range of metrics:
  1. Per-sample absolute percent error: |pred_ATP - ATP| / ATP * 100
  2. Per-sample percent error relative to the predicted labelâ€™s ATP range
  3. Per-sample percentile error: |pred_pct - actual_pct| * 100
  4. Per-label metrics:
       â€¢ sample count
       â€¢ classification accuracy
       â€¢ mean absolute percent error
       â€¢ mean range-normalized percent error
       â€¢ mean percentile error
       â€¢ pairwise ordering accuracy (only among correctly classified samples)
  5. Overall weighted averages of the above metrics (weighted by sample count per label)
  6. Overall pairwise ordering accuracy (among all samples)
All results are printed in a formatted table and summary.
"""

import pandas as pd
import numpy as np
import json
import itertools
import re
from sklearn.metrics import r2_score


def compute_bin_edges(mapping_dict, num_bins=8):
    """
    æ ¹æ®åŸå§‹ATPæ˜ å°„ï¼Œè®¡ç®—log10(ATP)åçš„åˆ†ç®±è¾¹ç•Œã€‚

    å‚æ•°:
        mapping_dict: dictï¼Œå›¾åƒè·¯å¾„åˆ°ATPå€¼çš„æ˜ å°„
        num_bins: intï¼Œåˆ†ç®±æ•°é‡ï¼ˆé»˜è®¤8ä¸ªç®±ï¼Œå¯¹åº”9ä¸ªè¾¹ç•Œï¼‰

    è¿”å›:
        bin_edges: np.ndarrayï¼Œé•¿åº¦ä¸º num_bins+1 çš„æ•°ç»„
    """
    atp_values = list(mapping_dict.values())
    log_atp_values = [np.log10(v) for v in atp_values]
    min_val, max_val = min(log_atp_values), max(log_atp_values)
    bin_edges = np.linspace(min_val - 1e-9, max_val + 1e-9, num_bins + 1)

    # ç»Ÿè®¡æ¯ä¸ª bin ä¸­çš„æ ·æœ¬æ•°
    bin_counts = np.histogram(log_atp_values, bins=bin_edges)[0]

    # æ‰¾å‡ºæœ€å¤§ bin æ ·æœ¬æ•°ï¼Œå¹¶è®¡ç®—å…¶10%
    max_bin_count = max(bin_counts)
    threshold = max_bin_count * 0.1

    # ç´¯åŠ å‰å‡ ä¸ª bin çš„æ ·æœ¬æ•°ï¼Œç›´åˆ°è¶…è¿‡é˜ˆå€¼
    cumulative = 0
    concat_bin_num = 0
    for count in bin_counts:
        cumulative += count
        concat_bin_num += 1
        if cumulative >= threshold:
            break
    return bin_edges, concat_bin_num


def main():
    df_list = ['pred_updated_AD_MutiHead_class12_44473515.csv','pred_updated_AD_MutiHead_class12.csv','pred_updated_googlenet_57797951.csv','pred_updated_inception_55565795.csv',
               'pred_updated_resnet_63536210.csv','pred_updated_vgg_64370553.csv',
               'pred_updated_class6_55300865.csv','pred_updated_class7_59445784.csv',
               'pred_updated_class8_55450629.csv','pred_updated_class9_58213844.csv',
               'pred_updated_class10_54893535.csv','pred_updated_class11_53686040.csv',
               'pred_updated_class12_49835097.csv','pred_updated_class13_58212806.csv',
               'pred_updated_class14_59482828.csv']
    bin_list = [12,12,12,12,12,12,6,7,8,9,10,11,12,13,14]
    df_list = ['pred_updated_resnet_MutiQ.csv','pred_updated_googlenet_MutiQ.csv',
               'pred_updated_inception_MutiQ.csv','pred_updated_vgg_MutiQ.csv',
               'pred_updated_AD_MutiHead_class6_53070808.csv', 'pred_updated_AD_MutiHead_class7_49840277.csv',
               'pred_updated_AD_MutiHead_class8_48337726.csv', 'pred_updated_AD_MutiHead_class9_49760909.csv',
               'pred_updated_AD_MutiHead_class10_46872753.csv', 'pred_updated_AD_MutiHead_class11_48507234.csv',
               'pred_updated_AD_MutiHead_class12_44097247.csv', 'pred_updated_AD_MutiHead_class13_46264555.csv',
               'pred_updated_AD_MutiHead_class14_45502575.csv']
    bin_list = [12,12,12,12, 6, 7, 8, 9, 10, 11, 12, 13, 14]
    # df_list = ['pred_updated_class12_49835097.csv']
    # bin_list = [12]
    # è¯»å–./dara/val_mapping.json
    with open('./data/val_mapping.json', 'r', encoding='utf-8') as f:
        val_mapping = json.load(f)
        # æŠŠkeyä¸­æ‰€æœ‰çš„image_2025æ›¿æ¢ä¸ºprocessed_images
        val_mapping = {k.replace('image_2025', 'processed_images'): v for k, v in val_mapping.items()}
        # æŠŠ\\æ›¿æ¢ä¸º/
        val_mapping = {k.replace('\\', '/'): v for k, v in val_mapping.items()}
    model_mae_bins = {}  # å­˜å‚¨æ¯ä¸ªæ¨¡å‹æ¯ä¸ªATPåŒºé—´çš„MAEåˆ—è¡¨
    # å¾ªç¯
    for k_num in range(len(df_list)):
        df_name = df_list[k_num]
        print(f"æ­£åœ¨å¤„ç†æ–‡ä»¶: {df_name}")
        # 1. åŠ è½½é¢„æµ‹ç»“æœ
        df = pd.read_csv(f'./data/{df_name}')
        num_bins = bin_list[k_num]
        # ç­›é€‰åœ¨ val_mapping ä¸­çš„æ ·æœ¬
        df = df[df['image_path'].isin(val_mapping.keys())].reset_index(drop=True)

        # def extract_lt_number(path):
        #     match = re.search(r'LT(\d+)', path)
        #     return int(match.group(1)) if match else -1
        # def extract_plate_order(path):
        #     match = re.search(r'[Pp]late(\d+)', path)
        #     return int(match.group(1)) if match else 99  # æœªåŒ¹é…çš„æ”¾åœ¨æœ€å
        # # æå–è·¯å¾„æœ€å7ä½ï¼ˆç”¨äºå­—å…¸åºï¼‰
        # def extract_last7(path):
        #     return str(path)[-7:]
        # # æ·»åŠ åˆ—
        # df['LT_num'] = df['image_path'].apply(extract_lt_number)
        # df['plate_order'] = df['image_path'].apply(extract_plate_order)
        # df['last7'] = df['image_path'].apply(extract_last7)
        # # æ’åºï¼šå…ˆæŒ‰ LTã€å†æŒ‰ plateï¼Œå†æŒ‰è·¯å¾„æœ«å°¾7å­—ç¬¦çš„å­—å…¸åº
        # df = df.sort_values(by=['LT_num', 'plate_order', 'last7'], kind='stable').reset_index(drop=True)
        # # ä¿å­˜æ’åºåçš„ç»“æœ
        # df.to_csv('./data/pred_sorted_AD_MutiHead_class12_44473515.csv', index=False)

        # 2. åŠ è½½å®Œæ•´ mapping å¹¶æ„å»º label_ranges
        mapping_file = './data/processed_image_atp_mapping.json'
        with open(mapping_file, 'r', encoding='utf-8') as f:
            full_mapping = json.load(f)
        bin_edges, concat_bin_num = compute_bin_edges(full_mapping, num_bins=num_bins)
        # æ„å»ºæ¯ä¸ª label çš„ log10(ATP) åŒºé—´
        label_ranges = {0: (bin_edges[0], bin_edges[concat_bin_num])}
        for i in range(concat_bin_num, len(bin_edges) - 1):
            label_ranges[i - concat_bin_num +1] = (bin_edges[i], bin_edges[i + 1])

        # ä¿®æ”¹labelåˆ—çš„å€¼ä¸ºatpçœŸæ­£çš„å¯¹åº”åŒºé—´
        for i in range(len(df)):
            atp = df.loc[i, 'ATP']
            atp = np.log10(atp)
            # æŸ¥æ‰¾atpåœ¨å“ªä¸ªåŒºé—´
            for j in range(len(label_ranges)):
                low_log, high_log = label_ranges[j]
                if low_log <= atp < high_log:
                    df.loc[i,"label"] = j
                    break


        # 3. è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„è¯¯å·®æŒ‡æ ‡
        df['MAE_diff'] = np.abs(df['pred_ATP'] - df['ATP'])
        # 3.1 ç»å¯¹ç™¾åˆ†è¯¯å·®: |pred_ATP - ATP| / ATP * 100
        df['MAE_pct'] = np.abs(df['pred_ATP'] - df['ATP']) / df['ATP'] * 100



        # 3.2 ç›¸å¯¹äºé¢„æµ‹ label èŒƒå›´çš„ç™¾åˆ†è¯¯å·®
        def compute_range_error(row):
            low_log, high_log = label_ranges[int(row['pred_label'])]
            range_atp = 10**high_log - 10**low_log
            return np.abs(row['pred_ATP'] - row['ATP']) / (range_atp + 1e-12) * 100
        df['range_MAE_pct'] = df.apply(compute_range_error, axis=1)

        # 3.3 è®¡ç®—å®é™…åˆ†ä½ actual_pctï¼Œå¹¶è®¡ç®—åˆ†ä½è¯¯å·®
        def compute_actual_pct(row):
            # ä»¥çœŸå® label çš„åŒºé—´è®¡ç®—å®é™…åˆ†ä½
            low_log, high_log = label_ranges[int(row['label'])]
            actual_log = np.log10(row['ATP'])
            pct = (actual_log - low_log) / (high_log - low_log + 1e-12)
            return np.clip(pct, 0.0, 1.0)
        df['actual_pct'] = df.apply(compute_actual_pct, axis=1)
        # 3.4 åˆ†ä½è¯¯å·®ç™¾åˆ†æ¯”: |pred_pct - actual_pct| * 100
        df['pct_error'] = np.abs(df['pred_pct'] - df['actual_pct']) * 100

        # 4. è®¡ç®—æ¯ä¸ª label çš„æŒ‡æ ‡
        per_label = []
        for label, grp in df.groupby('label'):
            count = len(grp)
            cls_acc = (grp['pred_label'] == grp['label']).mean()
            # åªåœ¨æ­£ç¡®åˆ†ç±»æ ·æœ¬ä¸Šè®¡ç®—åç»­å›å½’æŒ‡æ ‡
            # correct = grp[grp['pred_label'] == label].reset_index(drop=True)
            correct = grp.reset_index(drop=True)
            mae_diff = correct['MAE_diff'].mean() if len(correct)>0 else np.nan
            mae_pct = correct['MAE_pct'].mean() if len(correct)>0 else np.nan
            range_mae_pct = correct['range_MAE_pct'].mean() if len(correct)>0 else np.nan
            pct_mae = correct['pct_error'].mean() if len(correct)>0 else np.nan

            # è®¡ç®—æ­£ç¡®åˆ†ç±»æ ·æœ¬çš„ä¸¤ä¸¤æ’åºå‡†ç¡®ç‡
            n_corr = len(correct)
            if n_corr < 2:
                ordering_acc = np.nan
            else:
                total, corr_pairs = 0, 0
                sig_total, sig_corr_pairs = 0, 0

                # è·å–è¯¥æ ‡ç­¾çš„èŒƒå›´
                low_log, high_log = label_ranges[label]
                range_threshold = (10 ** high_log - 10 ** low_log) * 0.1

                for i, j in itertools.combinations(range(n_corr), 2):
                    actual_diff = correct.loc[i, 'ATP'] - correct.loc[j, 'ATP']
                    pred_diff   = correct.loc[i, 'pred_ATP'] - correct.loc[j, 'pred_ATP']
                    if actual_diff * pred_diff > 0:
                        corr_pairs += 1
                    total += 1

                    if abs(actual_diff) > range_threshold:
                        sig_total += 1
                        if actual_diff * pred_diff > 0:
                            sig_corr_pairs += 1

                ordering_acc = corr_pairs / total
                significant_ordering_acc = sig_corr_pairs / sig_total if sig_total > 0 else np.nan


            per_label.append({
                'label': label,
                'count': count,
                'classification_accuracy': cls_acc,
                'mean_MAE_diff': mae_diff,
                'mean_MAE_pct': mae_pct,
                'mean_range_MAE_pct': range_mae_pct,
                'mean_pct_error': pct_mae,
                'pairwise_ordering_acc': ordering_acc,
                'significant_pairwise_ordering_acc': significant_ordering_acc

            })
        metrics_df = pd.DataFrame(per_label).set_index('label')

        # 5. è®¡ç®—æ•´ä½“åŠ æƒæŒ‡æ ‡
        total_samples = metrics_df['count'].sum()
        weighted = {}
        for col in ['classification_accuracy','mean_MAE_diff', 'mean_MAE_pct', 'mean_range_MAE_pct', 'mean_pct_error', 'pairwise_ordering_acc','significant_pairwise_ordering_acc']:
            weighted[col] = (metrics_df[col] * metrics_df['count']).sum() / total_samples

        # 6. è®¡ç®—å…¨ä½“ä¸¤ä¸¤æ’åºå‡†ç¡®ç‡
        # df = df[df['pred_label'] == df['label']].reset_index(drop=True)
        n_all = len(df)
        if n_all < 2:
            overall_ordering_acc = np.nan
        else:
            total_pairs, corr_pairs = 0, 0
            for i, j in itertools.combinations(range(n_all), 2):
                actual_diff = df.loc[i, 'ATP'] - df.loc[j, 'ATP']
                pred_diff   = df.loc[i, 'pred_ATP'] - df.loc[j, 'pred_ATP']
                if actual_diff * pred_diff > 0:
                    corr_pairs += 1
                total_pairs += 1
            overall_ordering_acc = corr_pairs / total_pairs

        # 7. æ‰“å°ç»“æœ
        pd.set_option('display.float_format', '{:.4f}'.format)
        pd.set_option('display.max_columns', None)
        pd.set_option('display.width', None)
        pd.set_option('display.max_rows', None)
        print("\n=== Per-Label Metrics ===")
        print(metrics_df.to_string(), "\n")

        print(f"=== Overall Weighted Metrics in {df_name} ===")
        for name, val in weighted.items():
            print(f"{name}: {val:.4f}")
        print(f"overall_pairwise_ordering_accuracy: {overall_ordering_acc:.4f}")

        # è¾“å‡ºMAPE
        mape = (np.abs(df['pred_ATP'] - df['ATP']) / (df['ATP'] + 1e-8)).mean() * 100
        print(f"ğŸ“Š MAPE: {mape:.2f}%")

        # è¾“å‡ºç›¸å…³ç³»æ•°
        # corr = df['pred_ATP'].corr(df['ATP'])
        corr = r2_score(df['pred_ATP'], df['ATP'])
        print(f"ğŸ“Š r2: {corr:.4f}")


        # # ========================
        # # åˆ†ç±»é¢„æµ‹æ­£ç¡®å’Œé”™è¯¯çš„ ATP MAE
        # # ========================
        correct_df = df[df['label'] == df['pred_label']]
        incorrect_df = df[df['label'] != df['pred_label']]
        conf_df = df[df['conf'] > 0.5]
        # è®¡ç®— MAE
        if not correct_df.empty:
            correct_mae = (correct_df['pred_ATP'] - correct_df['ATP']).abs().mean()
            print(f"âœ… MAE (é¢„æµ‹æ­£ç¡®): {correct_mae:.4f}")
        else:
            print("âš ï¸ æ²¡æœ‰é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬")
        if not incorrect_df.empty:
            incorrect_mae = (incorrect_df['pred_ATP'] - incorrect_df['ATP']).abs().mean()
            print(f"âŒ MAE (é¢„æµ‹é”™è¯¯): {incorrect_mae:.4f}")
        else:
            print("âš ï¸ æ²¡æœ‰é¢„æµ‹é”™è¯¯çš„æ ·æœ¬")
        if not conf_df.empty:
            conf_mae = (conf_df['pred_ATP'] - conf_df['ATP']).abs().mean()
            print(f"âœ… MAE (conf > 0.5): {conf_mae:.4f}")


        # 8. è®¡ç®— ATP å°äº 500000 çš„æ ·æœ¬çš„ MAE
        # 8. å°†ATPåˆ’åˆ†ä¸º10æ®µï¼Œå¹¶è®¡ç®—æ¯æ®µçš„MAE
        atp_values = df['ATP']
        min_atp, max_atp = atp_values.min(), atp_values.max()
        bin_edges2 = np.linspace(min_atp, max_atp + 1e-6, 11)  # 10æ®µ => 11ä¸ªè¾¹ç•Œ

        mae_per_bin = []
        for i in range(10):
            bin_df = df[(df['ATP'] >= bin_edges2[i]) & (df['ATP'] < bin_edges2[i + 1])]
            if not bin_df.empty:
                mae = (bin_df['pred_ATP'] - bin_df['ATP']).abs().mean()
            else:
                mae = np.nan  # æ²¡æœ‰æ ·æœ¬
            mae_per_bin.append(mae)

        model_mae_bins[df_name] = mae_per_bin  # ä¿å­˜å½“å‰æ¨¡å‹çš„10æ®µMAE

        print("-" * 50)

    # æ„å»ºåŒºé—´æ ‡ç­¾
    bin_labels = ["{:.2e}-{:.2e}".format(bin_edges[i], bin_edges[i + 1]) for i in range(10)]
    # åˆ›å»º DataFrame
    mae_df = pd.DataFrame.from_dict(model_mae_bins, orient='index', columns=bin_labels)
    # æ‰“å° MAE DataFrame
    print("\n=== MAE per ATP bin (rows: models, columns: ATP bins) ===")
    print(mae_df)


if __name__ == "__main__":
    main()
